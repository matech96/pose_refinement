{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import sys\n",
    "sys.path.append(\"/workspace/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databases.datasets import (\n",
    "    Mpi3dTestDataset,\n",
    "    Mpi3dTrainDataset,\n",
    "    PersonStackedMucoTempDataset,\n",
    "    ConcatPoseDataset,\n",
    ")\n",
    "from model.videopose import TemporalModel, TemporalModelOptimized1f\n",
    "from training.preprocess import *\n",
    "from training.loaders import ChunkedGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = {\n",
    "        \"num_epochs\": 80,\n",
    "        \"preprocess_2d\": \"DepthposeNormalize2D\",\n",
    "        \"preprocess_3d\": \"SplitToRelativeAbsAndMeanNormalize3D\",\n",
    "        # training\n",
    "        \"optimiser\": \"adam\",\n",
    "        \"adam_amsgrad\": True,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"sgd_momentum\": 0,\n",
    "        \"batch_size\": 1024,\n",
    "        \"train_time_flip\": True,\n",
    "        \"test_time_flip\": True,\n",
    "        \"lr_scheduler\": {\"type\": \"multiplicative\", \"multiplier\": 0.95, \"step_size\": 1,},\n",
    "        # dataset\n",
    "        \"train_data\": \"mpii_train\",\n",
    "        \"pose2d_type\": \"hrnet\",\n",
    "        \"pose3d_scaling\": \"normal\",\n",
    "        \"megadepth_type\": \"megadepth_at_hrnet\",\n",
    "        \"cap_25fps\": True,\n",
    "        \"stride\": 2,\n",
    "        \"simple_aug\": True,  # augments data by duplicating each frame\n",
    "        \"model\": {\n",
    "            \"loss\": \"l1\",\n",
    "            \"channels\": 1024,\n",
    "            \"dropout\": 0.25,\n",
    "            \"filter_widths\": [3, 3, 3, 3],\n",
    "            \"layernorm\": False,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Mpi3dTrainDataset(\n",
    "    _config[\"pose2d_type\"],\n",
    "    _config[\"pose3d_scaling\"],\n",
    "    _config[\"cap_25fps\"],\n",
    "    _config[\"stride\"],\n",
    ")\n",
    "test_data = Mpi3dTestDataset(\n",
    "    _config[\"pose2d_type\"], _config[\"pose3d_scaling\"], eval_frames_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9142475 , 0.8918443 , 0.9529049 , 0.55906343, 0.94791263,\n",
       "       0.7756213 , 0.8251141 , 0.4155107 , 0.67124367, 0.25609845,\n",
       "       0.8118482 , 0.63151073, 0.7830368 , 0.7801824 , 0.81855637,\n",
       "       0.6617112 , 0.8385383 , 0.6991591 , 0.79960364], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.poses2d[9, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.prepare_sample(9)['pose2d'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.transform = None\n",
    "transforms_train = [\n",
    "    decode_trfrm(_config[\"preprocess_2d\"], globals())(train_data, cache=False),\n",
    "    decode_trfrm(_config[\"preprocess_3d\"], globals())(train_data, cache=False),\n",
    "]\n",
    "\n",
    "normalizer2d = transforms_train[0].normalizer\n",
    "normalizer3d = transforms_train[1].normalizer\n",
    "\n",
    "transforms_test = [\n",
    "    decode_trfrm(_config[\"preprocess_2d\"], globals())(test_data, normalizer2d),\n",
    "    decode_trfrm(_config[\"preprocess_3d\"], globals())(test_data, normalizer3d),\n",
    "]\n",
    "\n",
    "transforms_train.append(RemoveIndex())\n",
    "transforms_test.append(RemoveIndex())\n",
    "\n",
    "train_data.transform = SaveableCompose(transforms_train)\n",
    "test_data.transform = SaveableCompose(transforms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalModel(\n",
       "  (drop): Dropout(p=0.25, inplace=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (shrink): Conv1d(1024, 51, kernel_size=(1,), stride=(1,))\n",
       "  (expand_conv): Conv1d(42, 1024, kernel_size=(3,), stride=(1,), bias=False)\n",
       "  (expand_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers_conv): ModuleList(\n",
       "    (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(3,), bias=False)\n",
       "    (1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(9,), bias=False)\n",
       "    (3): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (4): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), dilation=(27,), bias=False)\n",
       "    (5): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (layers_bn): ModuleList(\n",
       "    (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TemporalModelOptimized1f(\n",
    "    train_data[[0]][\"pose2d\"].shape[-1],\n",
    "    MuPoTSJoints.NUM_JOINTS,\n",
    "    _config[\"model\"][\"filter_widths\"],\n",
    "    dropout=_config[\"model\"][\"dropout\"],\n",
    "    channels=_config[\"model\"][\"channels\"],\n",
    "    layernorm=_config[\"model\"][\"layernorm\"],\n",
    ")\n",
    "test_model = TemporalModel(\n",
    "    train_data[[0]][\"pose2d\"].shape[-1],\n",
    "    MuPoTSJoints.NUM_JOINTS,\n",
    "    _config[\"model\"][\"filter_widths\"],\n",
    "    dropout=_config[\"model\"][\"dropout\"],\n",
    "    channels=_config[\"model\"][\"channels\"],\n",
    "    layernorm=_config[\"model\"][\"layernorm\"],\n",
    ")\n",
    "model.cuda()\n",
    "test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = (model.receptive_field() - 1) // 2\n",
    "train_loader = ChunkedGenerator(\n",
    "    train_data, _config[\"batch_size\"], pad, _config[\"train_time_flip\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423828125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['valid_pose'].numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temporal_pose2d': torch.Size([1024, 81, 42]),\n",
       " 'pose3d': torch.Size([1024, 1, 51]),\n",
       " 'valid_pose': torch.Size([1024])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v.shape for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3d = model(data[\"temporal_pose2d\"].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8227, 0.9570, 0.9473, 0.7910, 0.9579, 0.9527, 0.9626, 0.9731, 0.9577,\n",
       "        0.9540, 0.9647, 0.9597, 0.9681, 0.7999])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data['temporal_pose2d'][0, 0, 2::3] * normalizer2d.std[2::3]) + normalizer2d.mean[2::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['temporal_pose2d'][0, 0, 2::3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.poses2d[0,:,2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_probs = [np.all(((data['temporal_pose2d'][:, :, 2::3] >= 0) & (data['temporal_pose2d'][:, :, 2::3] <= 1)).numpy()) for data in train_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    np.all(((data['temporal_pose2d'][:, :, 2::3] >= 0) & (data['temporal_pose2d'][:, :, 2::3] <= 1)).numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.all(((data['temporal_pose2d'][:, :, 2::3] <= 1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0553, 1.0014, 1.0082, 1.0124, 1.0116, 1.0231, 1.0001, 1.0168, 1.0074,\n",
       "        1.0004, 1.0051, 1.0141, 1.0183, 1.0208, 1.0180, 1.0122, 1.0060, 1.0039,\n",
       "        1.0130, 1.0086, 1.0208, 1.0096, 1.0082, 1.0054, 1.0246, 1.0054, 1.0139,\n",
       "        1.0007, 1.0305, 1.0597, 1.0226, 1.0431, 1.0040, 1.0130, 1.0012, 1.0005,\n",
       "        1.0110, 1.0138, 1.0211, 1.0126, 1.0113, 1.0249, 1.0023, 1.0121, 1.0007,\n",
       "        1.0217, 1.0284, 1.0114, 1.0209, 1.0377, 1.0416, 1.0058, 1.0078, 1.0236,\n",
       "        1.0193, 1.0000, 1.0100, 1.0079, 1.0189, 1.0044, 1.0187, 1.0090, 1.0191,\n",
       "        1.0426, 1.0362, 1.0352, 1.0169, 1.0000, 1.0017, 1.0075, 1.0048, 1.0018,\n",
       "        1.0018, 1.0039, 1.0021, 1.0256, 1.0029, 1.0145, 1.0087, 1.0054, 1.0250,\n",
       "        1.0294, 1.0149, 1.0041, 1.0058, 1.0014, 1.0204, 1.0010, 1.0129, 1.0235,\n",
       "        1.0292, 1.0129, 1.0063, 1.0028, 1.0007, 1.0083, 1.0021, 1.0018, 1.0113,\n",
       "        1.0019, 1.0318, 1.0023, 1.0121, 1.0054, 1.0250, 1.0294, 1.0029, 1.0036,\n",
       "        1.0112, 1.0195, 1.0045, 1.0064, 1.0004, 1.0113, 1.0212, 1.0090, 1.0200,\n",
       "        1.0002, 1.0022, 1.0051, 1.0195, 1.0305, 1.0060, 1.0011, 1.0014, 1.0072,\n",
       "        1.0012, 1.0062, 1.0168, 1.0074, 1.0031, 1.0094, 1.0047, 1.0113, 1.0252,\n",
       "        1.0091, 1.0138, 1.0110, 1.0042, 1.0091, 1.0128, 1.0103, 1.0164, 1.0098,\n",
       "        1.0428, 1.0022, 1.0050, 1.0090, 1.0051, 1.0094, 1.0002, 1.0010, 1.0323,\n",
       "        1.0319, 1.0322, 1.0123, 1.0175, 1.0185, 1.0211, 1.0256, 1.0044, 1.0338,\n",
       "        1.0004, 1.0305, 1.0060, 1.0080, 1.0012, 1.0264, 1.0139, 1.0183, 1.0023])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = data['temporal_pose2d'][:, :, 2::3]\n",
    "arr[arr > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 81, 42])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['temporal_pose2d'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
